{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c37a77d-ec9d-4e0e-bf80-d3f5efd11c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TextBlob in c:\\users\\pamme\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from TextBlob) (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from nltk>=3.1->TextBlob) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from nltk>=3.1->TextBlob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from nltk>=3.1->TextBlob) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from nltk>=3.1->TextBlob) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->TextBlob) (0.4.4)\n",
      "Requirement already satisfied: tweepy in c:\\users\\pamme\\anaconda3\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.11.1 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from tweepy) (2.26.0)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.0.0 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from requests<3,>=2.11.1->tweepy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from requests<3,>=2.11.1->tweepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from requests<3,>=2.11.1->tweepy) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from requests<3,>=2.11.1->tweepy) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from requests-oauthlib<2,>=1.0.0->tweepy) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "# Install Libraries #this is the latest version of textblob\n",
    "!pip3 install -U TextBlob\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e93e0bd-1383-4e91-a66f-c5c3d2772209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import webbrowser\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "# beacause textblob showed an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0300a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\pamme\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad3c9523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because SentimentIntensityAnalyzer was not running took this from github https://github.com/cjhutto/vaderSentiment/issues/8\n",
    "# and also https://stackoverflow.com/questions/43950777/importerror-no-module-named-vadersentiment/56953762\n",
    "# alt sentiment analysis: https://realpython.com/python-nltk-sentiment-analysis/\n",
    "# tweepy to xlx : https://stackoverflow.com/questions/46270698/how-to-export-data-from-tweepy-to-xlsx\n",
    "def __init__(self, model_file: str=None) -> None:\n",
    "        super().__init__()\n",
    "        # pip install nltk\n",
    "        # python > import nltk > nltk.download() > d > vader_lexicon\n",
    "        from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "        self.vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68397a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in c:\\users\\pamme\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "{'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compound': 0.4404}\n",
      "0.4404\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "vs = analyzer.polarity_scores(\"this is a good example\")\n",
    "print(str(vs))\n",
    "print(str(vs[\"compound\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dca12dc-9520-46a7-86a2-fe0d276b4bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "consumerKey = \"your key here\"\n",
    "consumerSecret = \"your key here\"\n",
    "accessToken = \"your token here\"\n",
    "accessTokenSecret = \"your token here\" \n",
    "auth = tweepy.OAuthHandler(consumerKey, consumerSecret)\n",
    "auth.set_access_token(accessToken, accessTokenSecret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c95b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\pamme\\anaconda3\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from wordcloud) (1.20.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from wordcloud) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: pycountry in c:\\users\\pamme\\anaconda3\\lib\\site-packages (20.7.3)\n"
     ]
    }
   ],
   "source": [
    "# wordcloud is not working showed a windows c++ version error - suggested to install a package https://stackoverflow.com/questions/38892509/how-to-install-wordcloud-package-in-python\n",
    "!pip install wordcloud\n",
    "!pip install pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14f3ae9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in c:\\users\\pamme\\anaconda3\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\pamme\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d9473d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Librariesfrom textblob import TextBlob\n",
    "import sys\n",
    "import tweepy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import pycountry\n",
    "import re\n",
    "import string \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from langdetect import detect\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f43e7185",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\pamme\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/43546593/error-message-with-nltk-sentiment-vader-in-python/45106654 for running sentiment\n",
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11f0a8b3-dec3-4bc7-93a9-62d2827f9b8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter keyword or hashtag to search:data analysis\n",
      "Please enter how many tweets to analyze:700\n"
     ]
    }
   ],
   "source": [
    "def percentage(part,whole):\n",
    "    return 100 * float(part)/float(whole)\n",
    "keyword = input(\"Please enter keyword or hashtag to search:\")\n",
    "noOfTweet = int(input (\"Please enter how many tweets to analyze:\"))\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keyword).items(noOfTweet)\n",
    "positive = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "polarity = 0\n",
    "tweet_list = []\n",
    "neutral_list = []\n",
    "negative_list = []\n",
    "positive_list = []\n",
    "for tweet in tweets:\n",
    " \n",
    " #print(tweet.text)\n",
    "     tweet_list.append(tweet.text)\n",
    "     analysis = TextBlob(tweet.text)\n",
    "     score = SentimentIntensityAnalyzer().polarity_scores(tweet.text)\n",
    "     neg = score['neg']\n",
    "     neu = score['neu']\n",
    "     pos = score['pos']\n",
    "     comp = score['compound']\n",
    "     polarity += analysis.sentiment.polarity\n",
    "if neg > pos:\n",
    "         negative_list.append(tweet.text)\n",
    "         negative += 1\n",
    "elif pos > neg:\n",
    "         positive_list.append(tweet.text)\n",
    "         positive += 1\n",
    "elif pos == neg:\n",
    "         neutral_list.append(tweet.text)\n",
    "         neutral += 1\n",
    "positive = percentage(positive, noOfTweet)\n",
    "negative = percentage(negative, noOfTweet)\n",
    "neutral = percentage(neutral, noOfTweet)\n",
    "polarity = percentage(polarity, noOfTweet)\n",
    "positive = format(positive, '.1f')\n",
    "negative = format(negative, '.1f')\n",
    "neutral = format(neutral, '.1f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92776cc",
   "metadata": {},
   "source": [
    "# the next steps will come once we're able to extract the tweets using tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aca04b05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number:  700\n",
      "positive number:  1\n",
      "negative number:  0\n",
      "neutral number:  0\n"
     ]
    }
   ],
   "source": [
    "#Number of Tweets (Total, Positive, Negative, Neutral)tweet_list = pd.DataFrame(tweet_list)\n",
    "neutral_list = pd.DataFrame(neutral_list)\n",
    "negative_list = pd.DataFrame(negative_list)\n",
    "positive_list = pd.DataFrame(positive_list)\n",
    "print(\"total number: \",len(tweet_list))\n",
    "print(\"positive number: \",len(positive_list))\n",
    "print(\"negative number: \", len(negative_list))\n",
    "print(\"neutral number: \",len(neutral_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41f33bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\pamme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\names.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pamme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     C:\\Users\\pamme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\state_union.zip.\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\pamme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\twitter_samples.zip.\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\pamme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\pamme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\pamme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pamme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying a different sentiment analysis library in ntlk: https://realpython.com/python-nltk-sentiment-analysis/\n",
    "nltk.download([\n",
    "\"names\",\n",
    "\"stopwords\",\n",
    "\"state_union\",\n",
    "\"twitter_samples\",\n",
    "\"movie_reviews\",\n",
    "\"averaged_perceptron_tagger\",\n",
    "\"vader_lexicon\",\n",
    "\"punkt\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0042a391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package shakespeare to\n",
      "[nltk_data]     C:\\Users\\pamme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package shakespeare is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('shakespeare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ded1c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb7d7269",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1671369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in words if w.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7772e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c3f4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "words: list[str] = nltk.word_tokenize(text)\n",
    "fd = nltk.FreqDist(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1eea36e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('...', 3), (',', 2), ('a', 2)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.most_common(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
